{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this notebook, we consider a case where we have two Normal distributions with the same variance but two potentially distinct means. we ask whether we can statistcally tell whether their means are different from each other. we answer this question in an empirical way. \n",
    "\n",
    "first, we create a null hypothesis where two Normal distributions have the same mean, i.e., they are the same distribution. we repeated draw pairs of sample sets from this distribution, aggregate the sampled mean differences and draw the histogram of these mean differences.\n",
    "\n",
    "second, we create a target hypothesis where two Normal distributions have two different means, separated by some value, and share the same variance of $1$ (or an identity covariance in the case of multi-dimensional Normal.) from each of these Normal distributions, we draw `n_samples` samples and estimate the sample mean. we then compute the sampled mean difference between two sets drawn from the two Normal distributions, respectively. we repeat this procedure many times and aggregate these sampled mean differences. we draw the histogram on top of the histogram of the null hypothesis from above.\n",
    "\n",
    "we will be able to see that the width of the second histogram shrinks rapidly as the number of samples we draw from each Normal distribution grows, implying that we can be increasingly more certain about the sampled mean difference if we have many samples from each of these two Normal distributions. this illustrates the idea of statistical power; in order for us to have confidence in our conclusion drawn from a set of samples, we better have enough of them.\n",
    "\n",
    "we also notice (perhaps obviously) that the mean of the sampled mean differences is centered at the true mean difference between two Normal distributions. according to this, we would need increasingly more samples in order to ensure that our conclusion from a single set of samples (or a single pair of sample sets) is solid if the true means are close to each other. this in fact tells us that statistical testing is not really about reject or not but about the degree to which we can trust our conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import some plotting libraries for drawing pretty plots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function fits a normal distribution to the given data.\n",
    "# it returns the mean and variance of the fitted normal distribution.\n",
    "def fit_normal(data):\n",
    "    mean = data.mean()\n",
    "    variance = data.var()\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function estimates the empirical cumulative distribution function of the data.\n",
    "# this function then computes the cumulative density of the given value.\n",
    "def ecdf(data, value):\n",
    "    data = np.sort(data)\n",
    "    n = len(data)\n",
    "    cdf = np.searchsorted(data, value, side='right') / n\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function draws a set of samples from a normal distribution with given mean and variance.\n",
    "# this function supports multi-dimensional data.\n",
    "# this function uses pyro for sampling.\n",
    "def draw_samples(mean, variance, num_samples):\n",
    "    samples = pyro.sample(\"samples\", \n",
    "                          pyro.distributions.Normal(mean, \n",
    "                                                    variance).expand([num_samples, \n",
    "                                                                      mean.shape[0]]))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function computes the kernel MMD between two sets of samples.\n",
    "# this function uses the Gaussian kernel for computing the MMD.\n",
    "def compute_mmd(samples1, samples2, bandwidth=1):\n",
    "    mmd = 0\n",
    "    for sample1 in samples1:\n",
    "        for sample2 in samples2:\n",
    "            mmd += torch.exp((-torch.norm(sample1 - sample2) ** 2) / (2 * bandwidth ** 2))\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw two sets of `n_samples` samples from a `n_dimensions`-dimensional \n",
    "# normal distribution with mean 0 and variance 1.\n",
    "# compute the difference in the means of the two sets of samples.\n",
    "# repeat this process `n_repeats` times.\n",
    "# return the list of mean differences.\n",
    "def compute_mean_diff(n_samples, n_dimensions, n_repeats):\n",
    "    mean_diffs = []\n",
    "    for _ in range(n_repeats):\n",
    "        samples1 = draw_samples(0 * torch.ones(n_dimensions), \n",
    "                                1 * torch.ones(n_dimensions), \n",
    "                                n_samples)\n",
    "        samples2 = draw_samples(0 * torch.ones(n_dimensions), \n",
    "                                1 * torch.ones(n_dimensions), \n",
    "                                n_samples)\n",
    "        mean_diffs.append(samples1.mean() - samples2.mean())\n",
    "    return mean_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now draw two sets of samples from two different normal distributions with different means.\n",
    "# compute the difference in the means of the two sets of samples.\n",
    "# repeat this process `n_repeats` times.\n",
    "# return the list of mean differences.\n",
    "def compute_mean_diff_diff_means(n_samples, n_dimensions, n_repeats, mean1, mean2, compute_p_value=False):\n",
    "    mean_diffs = []\n",
    "    if compute_p_value:\n",
    "        p_values = []\n",
    "    for _ in range(n_repeats):\n",
    "        samples1 = draw_samples(mean1, 1 * torch.ones(n_dimensions), n_samples)\n",
    "        samples2 = draw_samples(mean2, 1 * torch.ones(n_dimensions), n_samples)\n",
    "        if compute_p_value:\n",
    "            t_stat, p_value = stats.ttest_ind(samples1, samples2)\n",
    "            p_values.append(p_value)\n",
    "        mean_diffs.append(samples1.mean() - samples2.mean())\n",
    "    if compute_p_value:\n",
    "        return mean_diffs, p_values\n",
    "    return mean_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13142a64bd4b45c98e0d38f1b2682df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='n_samples', min=10), IntSlider(value=1, description='nâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_mean_diffs(n_samples, n_dimensions, n_repeats, mean1, mean2)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an interactive plot where we can vary the sample size, dimensionality of the data, and the mean difference.\n",
    "# this plot shows how the difference in the means of two sets of samples drawn from the same distribution changes.\n",
    "# this plot also shows how the difference in the means of two sets of samples drawn from two different distributions changes.\n",
    "def plot_mean_diffs(n_samples, n_dimensions, n_repeats, mean1, mean2):\n",
    "    mean_diffs_same = compute_mean_diff(n_samples, n_dimensions, 5_000)\n",
    "    mean_diffs_diff = compute_mean_diff_diff_means(n_samples, \n",
    "                                                   n_dimensions, \n",
    "                                                   n_repeats, \n",
    "                                                   mean1 * torch.ones(n_dimensions) / np.sqrt(n_dimensions), \n",
    "                                                   mean2 * torch.ones(n_dimensions) / np.sqrt(n_dimensions))\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    # use the normalized frequency for the y-axis.\n",
    "    sns.histplot([md.item() for md in mean_diffs_same], ax=ax, color='blue', label='Same Distribution', stat='density')\n",
    "    sns.histplot([md.item() for md in mean_diffs_diff], ax=ax, color='red', label='Different Distribution', stat='density')\n",
    "    ax.set_xlabel('Mean Difference')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Mean Difference vs Frequency')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# now create an interactive plot.\n",
    "# we can vary the sample size, dimensionality of the data, and the mean difference.\n",
    "interact_manual(plot_mean_diffs,\n",
    "                n_samples=widgets.IntSlider(min=10, max=100, step=1, value=100),\n",
    "                n_dimensions=widgets.IntSlider(min=1, max=10, step=1, value=1),\n",
    "                n_repeats=widgets.IntSlider(min=10, max=1000, step=10, value=100),\n",
    "                mean1=widgets.FloatSlider(min=-1, max=1, step=0.1, value=0),\n",
    "                mean2=widgets.FloatSlider(min=-1, max=1, step=0.1, value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
