{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this notebook, we consider a case where we have two classifiers with two different underlying accuracies. we assume this accuracy applies to each example independently, implying that whether the classifier correctly classifies a given example is sampled from a Bernoulli distribution with the mean set to the classifier's accuracy. We then want to know whether these two classifiers truly have two different accuracies given the sampled accuracies.\n",
    "\n",
    "there are two knobs of interest in this case. first, we can test the effect of having a different sized validation set `n_samples`. if the validation (test) set is too small, the variance of the accuracy difference is too large, and we cannot draw any sensible statiscal conclusion. this corresponds to the notion of 'statistical power'. second, we can test the effect of having multiple instantiations of the classifier, imitating the case of stochastic learning, by altering `acc_std`. if `acc_std` is too large (we assume it to be shared between the classifiers,) we cannot draw a concrete conclusion unless the true accuracy difference is large. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import some plotting libraries for drawing pretty plots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function draws a set of samples from a Bernoulli distribution with a given mean (accuracy).\n",
    "# this function uses pyro for sampling.\n",
    "def draw_samples(mean, num_samples):\n",
    "    samples = pyro.sample(\"samples\", \n",
    "                          pyro.distributions.Bernoulli(mean).expand([num_samples, 1]))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc_diff(n_samples, n_repeats, acc1, acc2, acc_std=0.):\n",
    "    acc_diffs = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        acc_diffs.append(torch.mean(draw_samples(torch.clip(torch.tensor(acc1+torch.randn(1).item() * acc_std), 0, 1), n_samples)) \n",
    "                         - torch.mean(draw_samples(torch.clip(torch.tensor(acc2+torch.randn(1).item() * acc_std), 0, 1), n_samples)))\n",
    "        \n",
    "    return acc_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "clip() received an invalid combination of arguments - got (float, float, float), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: clip() received an invalid combination of arguments - got (float, float, float), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "torch.clip(1.1, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fd0ad4f3fc4876afe9beb162bc271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='n_samples', max=1000, min=10), IntSlider(value=100, deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_acc_diffs(n_samples, n_repeats, acc1, acc2, acc_std)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an interactive plot where we can vary the sample size, dimensionality of the data, and the mean difference.\n",
    "# this plot shows how the difference in the means of two sets of samples drawn from the same distribution changes.\n",
    "# this plot also shows how the difference in the means of two sets of samples drawn from two different distributions changes.\n",
    "def plot_acc_diffs(n_samples, n_repeats, acc1, acc2, acc_std):\n",
    "    mean_diffs_same = compute_acc_diff(n_samples, 5_000, acc1, acc1, acc_std)\n",
    "    mean_diffs_diff = compute_acc_diff(n_samples, n_repeats, acc1, acc2, acc_std)\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    # use the normalized frequency for the y-axis.\n",
    "    sns.histplot([md.item() for md in mean_diffs_same], ax=ax, color='blue', label='Same Accuracy', stat='density')\n",
    "    sns.histplot([md.item() for md in mean_diffs_diff], ax=ax, color='red', label='Different Accuracies', stat='density')\n",
    "    ax.set_xlabel('Accuracy Difference')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Accuracy Difference vs Frequency')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# now create an interactive plot.\n",
    "# we can vary the sample size, dimensionality of the data, and the mean difference.\n",
    "interact_manual(plot_acc_diffs,\n",
    "                n_samples=widgets.IntSlider(min=10, max=1000, step=1, value=100),\n",
    "                n_repeats=widgets.IntSlider(min=10, max=1000, step=10, value=100),\n",
    "                acc1=widgets.FloatSlider(min=0, max=1, step=0.01, value=0.8),\n",
    "                acc2=widgets.FloatSlider(min=0, max=1, step=0.01, value=0.9),\n",
    "                acc_std=widgets.FloatSlider(min=0., max=1., step=0.0001, value=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
